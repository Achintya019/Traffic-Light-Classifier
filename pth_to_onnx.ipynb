{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.shufflenetv2 import ShuffleNetV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class LightClassifier(nn.Module):\n",
    "    def __init__(self, classes, load_param, debug=False):\n",
    "        super(LightClassifier, self).__init__()\n",
    "        \n",
    "        self.stage_repeats = [4, 8, 4]\n",
    "        self.stage_out_channels = [-1, 24, 48, 96, 192]\n",
    "        self.base = ShuffleNetV2(self.stage_repeats, self.stage_out_channels, load_param)\n",
    "\n",
    "        # Add a global average pooling layer\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Add a fully connected layer for classification\n",
    "        self.fc = nn.Linear(self.stage_out_channels[-1], classes)\n",
    "        \n",
    "        self.debug = debug\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.debug :\n",
    "            print(\"forward \", x.size())\n",
    "        _, _, P3 = self.base(x)\n",
    "        if self.debug :\n",
    "            print(\"base output \", P3.size())\n",
    "        x = self.global_pool(P3)\n",
    "        if self.debug :\n",
    "            print(\"after global pool \", x.size())\n",
    "        features = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        if self.debug :\n",
    "            print(\"after tensor flattening \", x.size())\n",
    "        logits = self.fc(features)\n",
    "        if self.debug :\n",
    "            print(\"final shape \", x.size())\n",
    "        return features, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize params from:./module/shufflenetv2.pth\n"
     ]
    }
   ],
   "source": [
    "model = LightClassifier(2, False, True)\n",
    "\n",
    "model.load_state_dict(torch.load('/home/achintya-trn0175/Downloads/trafficLightClassification/weights/tflt_700epochs/tflt_weight_loss:0.116813_240-epoch.pth'))\n",
    "dummy_input = torch.rand(1, 3, 192, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward  torch.Size([1, 3, 192, 192])\n",
      "base output  torch.Size([1, 192, 6, 6])\n",
      "after global pool  torch.Size([1, 192, 1, 1])\n",
      "after tensor flattening  torch.Size([1, 192, 1, 1])\n",
      "final shape  torch.Size([1, 192, 1, 1])\n",
      "Model has been converted to ONNX format.\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(model, dummy_input, 'model_weighted_smapler.onnx', export_params=True, opset_version=10, do_constant_folding=True, input_names=['input'], output_names=['output'])\n",
    "\n",
    "print(\"Model has been converted to ONNX format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpython\u001b[49m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albumentations version: 1.4.10\n",
      "PIL version: 10.3.0\n",
      "numpy version: 1.26.4\n",
      "argparse version: 1.1\n"
     ]
    }
   ],
   "source": [
    "from module.shufflenetv2 import ShuffleNetV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split, WeightedRandomSampler, Subset\n",
    "from utils.tool import *\n",
    "from utils.datasets import *\n",
    "from module.loss import DetectorLoss, CombinedLoss\n",
    "from trafficlight_cls import LightClassifier\n",
    "from torchvision import datasets, transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "from module.shufflenetv2 import ShuffleNetV2\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "\n",
    "print(f\"albumentations version: {A.__version__}\")\n",
    "print(f\"PIL version: {Image.__version__}\")\n",
    "\n",
    "print(f\"numpy version: {np.__version__}\")\n",
    "print(f\"argparse version: {argparse.__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
